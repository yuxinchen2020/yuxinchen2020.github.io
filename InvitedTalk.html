<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yuxin Chen - Wharton Statistics and Data Science</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yuxin Chen</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="Education.html">Experiences</a></div>
<div class="menu-item"><a href="Group.html">Group</a></div>
<div class="menu-item"><a href="Teaching.html">Teaching</a></div>
<div class="menu-item"><a href="Publications_year.html">Publications</a></div>
<div class="menu-item"><a href="Software.html">Software</a></div>
<div class="menu-item"><a href="Resume_Yuxin_CHEN.pdf">Resume</a></div>
<div class="menu-item"><a href="InvitedTalk.html">Talks</a></div>
<div class="menu-item"><a href="Workshops.html">Workshops</a></div>
</td>
<td id="layout-content">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y92NF7Q0DZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Y92NF7Q0DZ');
</script>
<h1>Tutorials, Short Courses and Lecture Series</h1>
<ul>
<li><p><a href="slides/ISIT2024_RL_tutorial.pdf">Information-Theoretic, Statistical and Algorithmic Foundations of Reinforcement Learning</a> <br /></p>
<ul>
<li><p>International Symposium on Information Theory (ISIT) 2024 </p>
</li></ul>
</li>
<li><p><a href="slides/spectral_method_slides.pdf">Spectral Methods for Data Science: A Statistical Perspective</a> <br /></p>
<ul>
<li><p>2023 Summer School on Theoretical Statistics, PKU BICMR & Math</p>
</li></ul>
</li>
<li><p>Statistical and Algorithmic Foundations of Reinforcement Learning <br /></p>
<ul>
<li><p>JSM 2023, together with Yuting Wei and Yuejie Chi</p>
</li></ul>
</li>
<li><p>Non-asymptotic Analysis for Reinforcement Learning <a href="slides/Model_Based_Sigmetrics.pdf">[Part 1]</a><a href="slides/Model_free_Sigmetrics.pdf">[Part 2]</a><a href="slides/Policy_Optimization_Sigmetrics.pdf">[Part 3]</a> <br /></p>
<ul>
<li><p>SIGMETRICS 2023, together with Yuting Wei and Yuejie Chi </p>
</li></ul>
</li>
<li><p><a href="slides/icassp2022_tutorial.pdf">Reinforcement Learning: Fundamentals, Algorithms, and Theory</a> <br /></p>
<ul>
<li><p>ICASSP 2022, together with Yuting Wei and Yuejie Chi</p>
</li></ul>
</li>
<li><p>Statistical and algorithmic foundations of reinforcement learning <br /></p>
<ul>
<li><p>ICSA Applied Statistics Symposium 2021, together with Yuting Wei, Yuejie Chi and Zhengyuan Zhou</p>
</li></ul>
</li>
<li><p>Nonconvex Optimization for High-Dimensional Signal Estimation: Spectral and Iterative Methods</p>
<ul>
<li><p>European Signal Processing Conference (EUSIPCO) 2020 <br /></p>
</li></ul>
</li>
<li><p><a href="slides/itw2018_tutorial.pdf">Taming nonconvexity in information science</a> </p>
<ul>
<li><p>ITW 2018, together with Yuejie Chi </p>
</li></ul>
</li>
<li><p><a href="slides/icassp2018_tutorial.pdf">Recent advances in nonconvex methods for high-dimensional estimation</a> <br /></p>
<ul>
<li><p>ICASSP 2018, together with Yuejie Chi and Yue Lu </p>
</li></ul>
</li>
<li><p>TRIAD Lecture Series 2019, Georgia Tech</p>
<ul>
<li><p><a href="slides/Gatech2019_TWF.pdf">The power of nonconvex optimization in solving random quadratic systems of equations</a></p>
</li>
<li><p><a href="slides/random_init_slides.pdf">Random initialization and implicit regularization in nonconvex statistical estimation</a></p>
</li>
<li><p><a href="slides/Alignment_slides_long.pdf">Projected power method: an efficient nonconvex algorithm for joint discrete assignment</a></p>
</li>
<li><p><a href="slides/ranking_asymmetry_slides.pdf">Spectral methods meets asymmetry: two recent stories</a> </p>
</li>
<li><p><a href="slides/NoisyMC_Inference_slides_Gatech.pdf">Inference and uncertainty quantification for noisy matrix completion</a></p>
</li>
</ul>

</li>
</ul>
<h1>A few invited Talks</h1>
<ol>
<li><p><a href="slides/Inference_NoisyMC_PCA_slides.pdf">Inference and uncertainty quantification for low-rank models</a> <br />


</p>
</li>
<li><p><a href="slides/Chen_MB_Q_NPG.pdf">Demystifying the efficiency of reinforcement learning: a few recent stories</a> <br />





</p>
</li>
<li><p><a href="slides/PG_NPG_slides.pdf">On the effectiveness of nonconvex optimization in reinforcement learning</a> <br />


</p>
</li>
<li><p><a href="slides/slides_TC.pdf">Taming nonconvexity in tensor completion: Fast convergence and uncertainty quantification</a> <br />



</p>
</li>
<li><p><a href="slides/slides_TC_NPG.pdf">Taming nonconvexity in statistical and reinforcement learning</a> <br />


</p>
</li>
<li><p><a href="slides/model_based_RL_slides.pdf">Breaking the sample size barrier in reinforcement learning via model-based approaches (a.k.a.&nbsp;plug-in approaches)</a> <br />

</p>
</li>
<li><p><a href="slides/RandomInit_Inference_Stability_slides.pdf">Nonconvex optimization meets statistics: a few recent stories</a> <br />





</p>
</li>
<li><p><a href="slides/NoisyMC_Inference_slides_Gatech.pdf">Inference and uncertainty quantification for noisy matrix completion</a> <br />

</p>
</li>
<li><p><a href="slides/NoisyMC_Inference_slides.pdf">Bridging convex and nonconvex optimization in noisy matrix completion: stability and uncertainty quantification</a> <br />





</p>
</li>
<li><p><a href="slides/NoisyMC_Asymmetry_slides.pdf">Stability, nonconvex optimization, and asymmetry in low-rank matrix estimation</a> <br />

</p>
</li>
<li><p><a href="slides/NoisyMC_slides.pdf">Noisy matrix completion: understanding statistical guarantees of convex relaxation via nonconvex optimization</a> <br />



</p>
</li>
<li><p><a href="slides/random_init_slides.pdf">Random initialization and implicit regularization in nonconvex statistical estimation</a> <br />


















</p>
</li>
<li><p><a href="slides/asymmetry_eigs_slides.pdf">Asymmetry helps: Eigenvalue and eigenvector analyses of asymmetrically perturbed low-rank matrices</a> <br />

</p>
</li>
<li><p><a href="slides/implicit_reg_slides.pdf">Implicit regularization in nonconvex statistical estimation</a> <br />  











</p>
</li>
<li><p><a href="slides/topK_slides.pdf">Spectral method and regularized MLE are both optimal for top-K ranking</a> <br />  

</p>
</li>
<li><p><a href="slides/Alignment_slides_long.pdf">The projected power method: a nonconvex algorithm for discrete problems</a> <br />







</p>
</li>
<li><p><a href="slides/Alignment_slides.pdf">The projected power method: an efficient algorithm for joint alignment from pairwise differences</a> <br /> 
















</p>
</li>
<li><p><a href="slides/TWF_slides.pdf">Solving random quadratic systems of equations is nearly as easy as solving linear systems</a> <br /> 














</p>
</li>
<li><p><a href="slides//TWF_slides.pdf">Modern optimization meets physics: recent progress on phase retrieval</a> <br />  






</p>
</li>
<li><p><a href="slides//matching_slides.pdf">Near-optimal joint object matching via convex relaxation</a> <br />








</p>
</li>
</ol>
<div id="footer">
<div id="footer-text">
Page generated 2025-04-23 10:43:51 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
(<a href="InvitedTalk.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
