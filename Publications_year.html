<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Yuxin Chen - Wharton Statistics and Data Science</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Yuxin Chen</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="Education.html">Experiences</a></div>
<div class="menu-item"><a href="Group.html">Group</a></div>
<div class="menu-item"><a href="Teaching.html">Teaching</a></div>
<div class="menu-item"><a href="Publications_year.html">Publications</a></div>
<div class="menu-item"><a href="Software.html">Software</a></div>
<div class="menu-item"><a href="Resume_Yuxin_CHEN.pdf">Resume</a></div>
<div class="menu-item"><a href="InvitedTalk.html">Talks</a></div>
<div class="menu-item"><a href="Workshops.html">Workshops</a></div>
</td>
<td id="layout-content">
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-Y92NF7Q0DZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-Y92NF7Q0DZ');
</script>
<h1>Publications </h1>
<h2>Monographs and overview articles</h2>

<table class="imgtable"><tr><td>
<p style="margin:3px;"></p>
<img src="images/spectral-methods-FnT.jpeg" alt="alt text" width="130 px" height="IMGLINKTARGET" />&nbsp;</td>
<td align="left"><p>
<ol>
<li><p><b>Statistical and Algorithmic Foundations of Reinforcement Learning</b> <br />   Y. Chi, <u>Y. Chen</u>, Y. Wei, <i>
INFORMS TutORial</i>, 2025. <a href="https://arxiv.org/pdf/2507.14444">[Arxiv]</a> 
</p>
</li>
<li><p><b>Spectral Methods for Data Science: A Statistical Perspective</b> <br />  <u>Y. Chen</u>, Y. Chi, J. Fan, C. Ma, <i>Foundations and Trends in Machine Learning</i>, vol. 14, no. 5, pp. 566â€“806, 2021. <a href="publications/SpectralMethods.pdf">[Arxiv]</a><a href="https://www.nowpublishers.com/article/Details/MAL-079">[FnT link]</a><a href="slides/spectral_method_slides.pdf">[Slides for PKU short course]</a> 
</p>
</li>
<li><p><b>Nonconvex Optimization Meets Low-Rank Matrix Factorization: An Overview</b>  <br />  Y. Chi, Y. Lu, <u>Y. Chen</u>, <i>IEEE Transactions on Signal Processing</i>, vol. 67, no. 20, pp. 5239-5269, October 2019 <b>(invited overview article)</b>.  <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8811622">[TSP version]</a><a href="publications/NcxOverview_Arxiv.pdf">[Arxiv]</a><a href="slides/Nonconvex_overview_slides.pdf">[slides]</a></p>
</li>
</ol>
<br>
<br>
</p>
</td></tr></table>

<h2>2025</h2>
<ol>
<li><p><b>Connections Between Reinforcement Learning with Feedback, Test-time Scaling, and Diffusion Guidance: An Anthology</b> <br />
Y. Jiao, <u>Y. Chen</u>, G. Li, 2025. <a href="https://arxiv.org/abs/2509.04372">[paper]</a> 
</p>
</li>
<li><p><b>Faster Diffusion Models via Higher-Order Approximation</b> <br />
G. Li*, Y. Zhou*, Y. Wei, <u>Y. Chen</u>, 2025 (*=equal contributions). <a href="publications/Diffusion_HighOrder.pdf">[paper]</a>
</p>
</li>
<li><p><b>Transformers Meet In-Context Learning: A Universal Approximation Theory</b> <br />
G. Li*, Y. Jiao*, Y. Huang, Y. Wei, <u>Y. Chen</u>, 2025 (*=equal contributions). <a href="publications/TransformerICL.pdf">[paper]</a><a href="slides/Transformer_ICL_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Low-Dimensional Adaptation of Diffusion Models: Convergence in Total Variation</b> <br />
J. Liang, Z. Huang, <u>Y. Chen</u>, 2025. <a href="publications/diffusion-low-dim.pdf">[paper]</a><a href="slides/Diffusion_low_dim_slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;accepted in part to COLT 2025</p>
</li>
</ol>
<h2>2024</h2>
<ol>
<li><p><b>Anytime Acceleration of Gradient Descent</b> <br />
Z. Zhang,  J. D. Lee, S. S. Du, <u>Y. Chen</u>, <i>Conference on Learning Theory (COLT)</i>, 2025. <a href="publications/Anytime_AGD.pdf">[paper]</a>
</p>
</li>
<li><p><b>Denoising Diffusion Probabilistic Models Are Optimally Adaptive to Unknown Low Dimensionality</b> <br />
Z. Huang, Y. Wei, <u>Y. Chen</u>, 2024. <a href="publications/DDPM-low-dim.pdf">[paper]</a>
</p>
</li>
<li><p><b>Stochastic Runge-Kutta Methods: Provable Acceleration of Diffusion Models</b> <br />
Y. Wu, <u>Y. Chen</u>, Y. Wei, 2024. <a href="publications/Stochastic_Runge_Kutta.pdf">[paper]</a>
</p>
</li>
<li><p><b>A Sharp Convergence Theory for The Probability Flow ODEs of Diffusion Models</b> <br />
G. Li, Y. Wei, Y. Chi, <u>Y. Chen</u>, 2024. <a href="publications/DiffusionODE.pdf">[paper]</a><a href="slides/Acc_diffusion_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Accelerating Convergence of Score-Based Diffusion Models, Provably</b> <br />
G. Li*, Y. Huang*, T. Efimov, Y. Wei, Y. Chi, <u>Y. Chen</u>, International Conference on Machine Learning (ICML), 2024 (*=equal contributions). <a href="publications/AccDiffusion.pdf">[paper]</a><a href="slides/Acc_diffusion_slides.pdf">[slides]</a><a href="https://github.com/TimofeyEfimov/AcceleratedDiffusionSamplers">[code]</a>



</p>
</li>
</ol>
<h2>2023</h2>
<ol>
<li><p><b>Settling the Sample Complexity of Online Reinforcement Learning</b> <br />
Z. Zhang, <u>Y. Chen</u>,  J. D. Lee, S. S. Du, <i>Journal of the ACM</i>, vol. 72, no. 3, pp. 1-63, 2025. <a href="publications/Optimal-OnlineRL.pdf">[paper]</a><a href="https://dl.acm.org/doi/10.1145/3733592">[JACM version]</a><a href="slides/Optimal_OnlineRL_slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in COLT 2024
</p>
</li>
<li><p><b>Optimal Multi-Distribution Learning</b> <br />
Z. Zhang, W. Zhan, <u>Y. Chen</u>, S. S. Du,  J. D. Lee, <i>Journal of the ACM</i>, vol. 72, no. 5, pp. 1-71, 2025. <a href="publications/MDL.pdf">[paper]</a><a href="slides/MDL_slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in COLT 2024
</p>
</li>
<li><p><b>Towards Non-Asymptotic Convergence for Diffusion-Based Generative Models</b> <br />
G. Li, Y. Wei, <u>Y. Chen</u>, Y. Chi, 2023. 
<i>International Conference on Learning Representations (ICLR)</i>, 2024. <a href="publications/DiffusionSGM.pdf">[paper]</a><a href="slides/Acc_diffusion_slides.pdf">[slides]</a>

</p>
</li>
<li><p><b>Deflated HeteroPCA: Overcoming the Curse of Ill-Conditioning in Heteroskedastic PCA</b> <br />
Y. Zhou, <u>Y. Chen</u>,  <i>Annals of Statistics</i>, vol. 53, no. 1, pp. 91-116, 2025.  <a href="publications/deflated_heteroPCA.pdf">[paper]</a><a href="https://projecteuclid.org/journals/annals-of-statistics/volume-53/issue-1/Deflated-HeteroPCA--Overcoming-the-curse-of-ill-conditioning-in/10.1214/24-AOS2456.full">[AoS version]</a><a href="slides/Deflated_HeteroPCA_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Heteroskedastic Tensor Clustering</b> <br />
Y. Zhou, <u>Y. Chen</u>,  2023 <a href="publications/tensor_clustering.pdf">[paper]</a><a href="slides/tensor_clusteing_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Minimax-Optimal Reward-Agnostic Exploration in Reinforcement Learning</b> <br />
G. Li, Y. Yan, <u>Y. Chen</u>, J. Fan, 2023. <a href="publications/Reward-free-exploration.pdf">[paper]</a><a href="slides/RFE_slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in COLT 2024
</p>
</li>
<li><p><b>Fast Computation of Optimal Transport via Entropy-Regularized Extragradient Methods</b> <br />
G. Li, Y. Chen, Y. Huang, Y. Chi, H. V. Poor, <u>Y. Chen</u>,  <i>SIAM Journal on Optimization</i>, vol. 35, no. 2, pp. 1330-1363, 2025 <a href="publications/OT_game.pdf">[paper]</a>
</p>
</li>
<li><p><b>Federated Natural Policy Gradient Methods for Multi-task Reinforcement Learning</b> <br />
T. Yang, S. Cen, Y. Wei, <u>Y. Chen</u>, Y. Chi, <i>Neural Information Processing Systems (NeurIPS)</i>, December 2024 <a href="publications/Federated_multitask_RL.pdf">[paper]</a>
</p>
</li>
<li><p><b>Reward-Agnostic Fine-Tuning: Provable Statistical Benefits of Hybrid Reinforcement Learning</b> <br />
G. Li, W. Zhan, J. D. Lee, Y. Chi, <u>Y. Chen</u>, <i>Neural Information Processing Systems (NeurIPS)</i>, December 2023. <a href="publications/Policy_finetuning.pdf">[paper]</a>
</p>
</li>
<li><p><b>The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model</b> <br />
L. Shi, G. Li, Y. Wei, <u>Y. Chen</u>, M. Geist, Y. Chi, <i>Neural Information Processing Systems (NeurIPS)</i>, December 2023. <a href="publications/DRO-Simulator.pdf">[paper]</a>
</p>
</li>
<li><p><b>Why MagNet: Quantifying the Complexity of Modeling Power Magnetic Material Characteristics</b> <br />
D. Serrano, H. Li, S. Wang, T. Guillod, M. Luo, V. Bansal, N. Jha, <u>Y. Chen</u>, C. R. Sullivan, and M. Chen, 
<i>IEEE Transactions on Power Electronics</i>, vol. 38, no. 11, pp. 14292-14316, Nov. 2023 <a href="https://ieeexplore.ieee.org/document/10169101">[paper]</a>
</p>
</li>
<li><p><b>How MagNet: Machine Learning Framework for Modeling Power Magnetic Material Characteristics</b> <br />
H. Li, D. Serrano, T. Guillod, S. Wang, E. Dogariu, A. Nadler, M. Luo, V. Bansal, N. Jha, <u>Y. Chen</u>, C. R. Sullivan, and M. Chen, 
<i>IEEE Transactions on Power Electronics</i>, vol. 38, no. 12, pp. 15829-15853, Dec. 2023 <a href="https://ieeexplore.ieee.org/abstract/document/10232863/">[paper]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;<b style="color: FireBrick">IEEE Transactions on Power Electronics (TPEL) Prize Paper Award (first place)</b>
</p>
</li>
</ol>
<h2>2022</h2>
<ol>
<li><p><b>Settling the Sample Complexity of Model-Based Offline Reinforcement Learning</b> <br />
G. Li, L. Shi, <u>Y. Chen</u>,  Y. Chi, Y. Wei,  <i>Annals of Statistics</i>,  vol. 52, no. 1, pp. 233-260, 2024. <a href="publications/offline_modelbased.pdf">[paper]</a><a href="https://projecteuclid.org/journals/annals-of-statistics/volume-52/issue-1/Settling-the-sample-complexity-of-model-based-offline-reinforcement-learning/10.1214/23-AOS2342.full">[AoS version]</a>
</p>
</li>
<li><p><b>Minimax-Optimal Multi-Agent RL in Markov Games With a Generative Model</b> <br />
G. Li, Y. Chi, Y. Wei, <u>Y. Chen</u>,  <i>Neural Information Processing Systems (NeurIPS)</i>, December 2022 <b>(selected as oral)</b>. <a href="publications/Markov_games_simulator.pdf">[paper]</a>
</p>
</li>
<li><p><b>Model-Based Reinforcement Learning Is Minimax-Optimal for Offline Zero-Sum Markov Games</b> <br />
Y. Yan, G. Li, <u>Y. Chen</u>, J. Fan, <i>Operations Research</i>, vol. 72, no. 6, pp. 2430â€“2445, Novemberâ€“December 2024. <a href="publications/model_based_offline_game.pdf">[paper]</a><a href="https://pubsonline.informs.org/doi/epdf/10.1287/opre.2022.0342">[OR version]</a>
</p>
</li>
<li><p><b>The Efficacy of Pessimism in Asynchronous Q-Learning</b> <br />
Y. Yan, G. Li, <u>Y. Chen</u>, J. Fan, <i>IEEE Transactions on Information Theory</i>, vol. 69, no. 11, pp. 7185 - 7219, Nov. 2023. <a href="publications/asyn_Q_pessimism.pdf">[paper]</a>
</p>
</li>
<li><p><b>Pessimistic Q-Learning for Offline Reinforcement Learning: Towards Optimal Sample Complexity</b> <br />
L. Shi, G. Li, Y. Wei, <u>Y. Chen</u>, Y. Chi, <i>International Conference on Machine Learning (ICML)</i>, July 2022. <a href="publications/Pessimistic_Qlearning.pdf">[paper]</a><a href="publications/Pessimistic_Qlearning_ICML.pdf">[ICML version]</a>
</p>
</li>
<li><p><b>MagNet: An Open-Source Database for Data-Driven Magnetic Core Loss Modeling</b> <br />
H. Li, D. Serrano, T. Guillod, E. Dogariu, A. Nadler, S. Wang, M. Luo, V. Bansal, <u>Y. Chen</u>, C. R. Sullivan, and M. Chen, 
<i>IEEE Applied Power Electronics Conference (APEC)</i>, 2022. <a href="https://ieeexplore.ieee.org/abstract/document/9773372/">[paper]</a><a href="https://github.com/PrincetonUniversity/Magnet">[Github repo]</a><a href="https://mag-net.princeton.edu/">[website]</a></p>
</li>
</ol>
<h2>2021</h2>
<ol>
<li><p><b>Softmax Policy Gradient Methods Can Take Exponential Time to Converge</b> <br />  G. Li, Y. Wei, Y. Chi, <u>Y. Chen</u>, <i>Mathematical Programming</i>, vol. 201, pp. 707-802, 2023. <a href="publications/SoftmaxPG_LB.pdf">[paper]</a><a href="https://link.springer.com/article/10.1007/s10107-022-01920-6">[MP version]</a><a href="slides/Softmax_Lower_Bound_slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/SoftmaxPG_LB_COLT.pdf">COLT 2021</a> 
</p>
</li>
<li><p><b>Is Q-Learning Minimax Optimal? A Tight Sample Complexity Analysis</b> <br />  G. Li, C. Cai, <u>Y. Chen</u>, Y. Wei, Y. Chi,  <i>Operations Research</i>,  vol. 72, no. 1, pp. 203-221, 2024. <a href="publications/SyncQlearning.pdf">[paper]</a><a href="https://pubsonline.informs.org/doi/epdf/10.1287/opre.2023.2450">[OR version]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/SyncQlearning_ICML.pdf">ICML 2021</a> 
</p>
</li>
<li><p><b>Policy Mirror Descent for Regularized Reinforcement Learning: A Generalized Framework with Linear Convergence</b> <br />  
W. Zhan*, S. Cen*, B. Huang, <u>Y. Chen</u>, J. D. Lee, Y. Chi, <i>SIAM Journal on Optimization</i>, vol. 33, no. 2, pp. 1061-1091, June 2023. (*=equal contributions) <a href="https://arxiv.org/abs/2105.11066">[paper]</a> 
</p>
</li>
<li><p><b>Inference for Heteroskedastic PCA with Missing Data</b> <br />
Y. Yan, <u>Y. Chen</u>, J. Fan, <i>Annals of Statistics</i>, vol. 52, no. 2, pp. 729-756, 2024. <a href="publications/Denoising_PCA_inference.pdf">[ArXiv]</a><a href="https://projecteuclid.org/journals/annals-of-statistics/volume-52/issue-2/Inference-for-heteroskedastic-PCA-with-missing-data/10.1214/24-AOS2366.full">[AoS version]</a><a href="slides/PCA_Inference_short.pdf">[slides]</a>
</p>
</li>
<li><p><b>Breaking the Sample Complexity Barrier to Regret-Optimal Model-free Reinforcement Learning</b> <br />
G. Li, L. Shi, <u>Y. Chen</u>, Y. Chi,  <i>Information and Inference: A Journal of the IMA</i>, vol. 12, no. 2, pp. 969-1043, June 2023. <a href="publications/model-free-exploration.pdf">[paper]</a><a href="slides/Model-free-exploration_slides.pdf">[slides]</a>  
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in NeurIPS 2021 <b>(selected as spotlight)</b>
</p>
</li>
<li><p><b>Sample-Efficient Reinforcement Learning Is Feasible for Linearly Realizable MDPs with Limited Revisiting</b> <br />
G. Li, <u>Y. Chen</u>, Y. Chi, Y. Gu, Y. Wei, <i>Neural Information Processing Systems (NeurIPS)</i>, December 2021. <a href="publications/LinearQ_Revisit.pdf">[paper]</a><a href="publications/LinearQ_Revisit_NeurIPS.pdf">[NeurIPS version]</a><a href="slides/Linear_realizability_slides.pdf">[slides]</a>  
</p>
</li>
<li><p><b>Minimax Estimation of Linear Functions of Eigenvectors in the Face of Small Eigen-Gaps</b> <br />  G. Li, C. Cai,  H. V. Poor, <u>Y. Chen</u>, <i>IEEE Transactions on Information Theory</i>, vol. 71, no. 2, pp. 1200-1247, 2025. <a href="publications/Eigenanalysis_linear_forms.pdf">[paper]</a>
</p>
</li>
</ol>
<h2>2020</h2>
<ol>
<li><p><b>Breaking the Sample Size Barrier in Model-Based Reinforcement Learning with a Generative Model</b> <br />  G. Li, Y. Wei, Y. Chi,  <u>Y. Chen</u>, <i>Operations Research</i>,  vol. 72, no. 1, pp. 222-236, 2024. <a href="publications/model_based_RL.pdf">[paper]</a><a href="https://pubsonline.informs.org/doi/epdf/10.1287/opre.2023.2451">[OR version]</a><a href="http://www.stat.cmu.edu/~ytwei/documents/slides/model-based-rl-slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/model_base_RL_neurips.pdf">NeurIPS 2020</a>
</p>
</li>
<li><p><b>Bridging Convex and Nonconvex Optimization in Robust PCA: Noise, Outliers, and Missing Data</b> <br /> <u>Y. Chen</u>, J. Fan, C. Ma, Y. Yan, <i>Annals of Statistics</i>, vol. 49, no. 5, pp. 2948-2971, Oct. 2021. <a href="publications/RPCA_noise.pdf">[paper]</a><a href="https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-5/Bridging-convex-and-nonconvex-optimization-in-robust-PCA--Noise/10.1214/21-AOS2066.full">[AoS version]</a>
</p>
</li>
<li><p><b>Convex and Nonconvex Optimization Are Both Minimax-Optimal for Noisy Blind Deconvolution under Random Designs</b> <br /> <u>Y. Chen</u>, J. Fan, B. Wang, Y. Yan, <i>Journal of the American Statistical Association</i>, vol. 118, no. 542, pp. 858-868, 2023. <a href="publications/BD_noise.pdf">[paper]</a>
</p>
</li>
<li><p><b>Fast Global Convergence of Natural Policy Gradient Methods with Entropy Regularization</b> <br />  S. Cen, C. Cheng, <u>Y. Chen</u>, Y. Wei, Y. Chi, <i>Operations Research</i>, vol. 70, no. 4, pp. 2563â€“2578, 2022. <a href="publications/NPG_reg.pdf">[paper]</a><a href="https://pubsonline.informs.org/doi/epdf/10.1287/opre.2021.2151">[OR version]</a><a href="slides/EntropyNPG_slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;<b style="color: FireBrick">INFORMS George Nicholson award finalist</b>
</p>
</li>
<li><p><b>Sample Complexity of Asynchronous Q-Learning: Sharper Analysis and Variance Reduction</b> <br />  G. Li, Y. Wei, Y. Chi, Y. Gu, <u>Y. Chen</u>, <i>IEEE Transactions on Information Theory</i>, vol. 68, no. 1, pp. 448-473, Jan. 2022. <a href="publications/AsynQlearning.pdf">[paper]</a><a href="slides/Async_Qlearning_slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/AsynQlearning_NeurIPS.pdf">NeurIPS 2020</a>
</p>
</li>
<li><p><b>Uncertainty Quantification for Nonconvex Tensor Completion: Confidence Intervals, Heteroscedasticity and Optimality</b> <br />  C. Cai,  H. V. Poor, <u>Y. Chen</u>, <i>IEEE Transactions on Information Theory</i>, vol. 69, no. 1, pp. 407-452, Jan. 2023. <a href="publications/TC_inference.pdf">[paper]</a><a href="slides/slides_TC.pdf">[slides]</a> 
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/TC_inference_ICML.pdf">ICML 2020</a>
</p>
</li>
<li><p><b>Tackling Small Eigen-gaps: Fine-Grained Eigenvector Estimation and Inference under Heteroscedastic Noise</b> <br />  C. Cheng, Y. Wei, <u>Y. Chen</u>, <i>IEEE Transactions on Information Theory</i>, vol. 67, no. 11, pp. 7380-7419, Nov. 2021. <a href="publications/eigenvector_inference.pdf">[paper]</a><a href="slides/inference_asymmetry_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Learning Mixtures of Low-Rank Models</b> <br />  Y. Chen, C. Ma, H. V. Poor, <u>Y. Chen</u>, <i>IEEE Transactions on Information Theory</i>, vol. 67, no. 7, pp. 4613-4636, July 2021. <a href="publications/mixed-matrix-sensing.pdf">[paper]</a> 
</p>
</li>
<li><p><b>MagNet: A Machine Learning Framework for Magnetic Core Loss Modeling</b> <br /> H. Li, S. R. Lee, M. Luo, C. R. Sullivan, <u>Y. Chen</u>, M. Chen, <i>IEEE Workshop on Control and Modeling of Power Electronics (COMPEL)</i>, 2020. <a href="https://ieeexplore.ieee.org/document/9265869">[paper]</a></p>
</li>
</ol>
<h2>2019</h2>
<ol>
<li><p><b>Nonconvex Low-Rank Tensor Completion from Noisy Data</b> <br />  C. Cai, G. Li, H. V. Poor, <u>Y. Chen</u>, <i>Operations Research</i>, vol. 70, no. 2, pp. 1219â€“1237, 2022. <a href="publications/NonconvexTC.pdf">[paper]</a><a href="https://pubsonline.informs.org/doi/pdf/10.1287/opre.2021.2106">[OR version]</a><a href="slides/slides_TC.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/NonconvexTC_NIPS.pdf">NeurIPS 2019</a>
</p>
</li>
<li><p><b>Inference and Uncertainty Quantification for Noisy Matrix Completion</b> <br /> <u>Y. Chen</u>, J. Fan, C. Ma, Y. Yan,  <i>Proceedings of the National Academy of Sciences (PNAS)</i>, vol. 116, no. 46, pp. 22931â€“22937, Nov. 2019 (direct submission). <a href="https://www.pnas.org/content/pnas/116/46/22931.full.pdf">[PNAS version]</a><a href="publications/MC_inference.pdf">[full paper]</a><a href="slides/NoisyMC_Inference_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Subspace Estimation from Unbalanced and Incomplete Data Matrices:  $\ell_{2,\infty}$ Statistical Guarantees </b> <br />  C. Cai, G. Li, Y. Chi, H. V. Poor, <u>Y. Chen</u>,  <i>Annals of Statistics</i>, vol. 49, no. 2, pp. 944-967, 2021. <a href="publications/unbalanced_PCA.pdf">[paper]</a><a href="https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-2/Subspace-estimation-from-unbalanced-and-incomplete-data-matrices--%e2%84%932/10.1214/20-AOS1986.full">[AoS version]</a>
</p>
</li>
<li><p><b>Noisy Matrix Completion: Understanding Statistical Guarantees for  Convex Relaxation via Nonconvex Optimization</b> <br /> <u>Y. Chen</u>, Y. Chi, J. Fan, C. Ma, Y. Yan,  <i>SIAM Journal on Optimization</i>, vol. 30, no. 4, pp. 3098â€“3121, 2020. <a href="publications/NoisyMC.pdf">[paper]</a><a href="https://epubs.siam.org/doi/pdf/10.1137/19M1290000">[SIOPT version]</a><a href="slides/NoisyMC_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Communication-Efficient Distributed Optimization in Networks with Gradient Tracking and Variance Reduction</b> <br /> B. Li, S. Cen, <u>Y. Chen</u>, Y. Chi,  <i>Journal of Machine Learning Research</i>, vol. 21, no. 180, pp. 1-51, 2020. <a href="https://arxiv.org/abs/1909.05844">[paper]</a><a href="https://github.com/liboyue/Network-Distributed-Algorithm">[code]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in AISTATS 2020</p>
</li>
</ol>
<h2>2018</h2>
<ol>
<li><p><b>Gradient Descent with Random Initialization: Fast Global Convergence for Nonconvex Phase Retrieval</b>  <br />  <u>Y. Chen</u>, Y. Chi, J. Fan, C. Ma, <i>Mathematical Programming</i>, vol. 176, no. 1-2, pp. 5-37, July 2019.  <a href="publications/random_init_PR.pdf">[paper]</a><a href="publications/random_init_PR_MP.pdf">[MP version]</a><a href="slides/random_init_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Asymmetry Helps: Eigenvalue and Eigenvector Analyses of Asymmetrically Perturbed Low-Rank Matrices</b> <br /> <u>Y. Chen</u>, C. Cheng, J. Fan, <i>Annals of Statistics</i>, vol. 49, no. 1, pp. 435-458, 2021. <a href="publications/asymmetric_eigens.pdf">[paper]</a><a href="https://projecteuclid.org/journals/annals-of-statistics/volume-49/issue-1/Asymmetry-helps--Eigenvalue-and-eigenvector-analyses-of-asymmetrically-perturbed/10.1214/20-AOS1963.full">[AoS version]</a><a href="slides/asymmetry_eigs_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Nonconvex Matrix Factorization from Rank-One Measurements</b> <br />  Y. Li, C. Ma, <u>Y. Chen</u>, Y. Chi,  <i>IEEE Transactions on Information Theory</i>, vol. 67, no. 3, pp. 1928-1950, March 2021. <a href="https://arxiv.org/abs/1802.06286">[paper]</a> 
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/NonconvexRankOne_AISTATS.pdf">AISTATS 2019</a>
</p>
</li>
</ol>
<h2>2017</h2>
<ol>
<li><p><b>Implicit Regularization in Nonconvex Statistical Estimation:<br /> Gradient Descent Converges Linearly for Phase Retrieval, Matrix Completion, and Blind Deconvolution</b>  <br />  C. Ma, K. Wang, Y. Chi, <u>Y. Chen</u>, <i>Foundations of Computational Mathematics</i>, vol. 20, no. 3, pp. 451-632, June 2020.  <a href="https://link.springer.com/content/pdf/10.1007%2Fs10208-019-09429-9.pdf">[FoCM version]</a><a href="publications/ImplicitReg_main.pdf">[main text]</a><a href="publications/ImplicitReg_supp.pdf">[supplement]</a><a href="publications/ImplicitReg.pdf">[Arxiv]</a><a href="slides/implicit_reg_slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;<b style="color: FireBrick">SIAM Activity Group on Imaging Science Best Paper Prize</b>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/ImplicitReg_ICML.pdf">ICML 2018</a> 
</p>
</li>
<li><p><b>Spectral Method and Regularized MLE Are Both Optimal for Top-<i>K</i> Ranking</b>  <br />  <u>Y. Chen</u>, J. Fan, C. Ma, K. Wang, <i>Annals of Statistics</i>, vol. 47, no. 4, pp. 2204-2235, August 2019.   <a href="publications/topK_AOS.pdf">[paper]</a><a href="publications/topK.pdf">[Arxiv]</a><a href="https://projecteuclid.org/journals/annals-of-statistics/volume-47/issue-4/Spectral-method-and-regularized-MLE-are-both-optimal-for-top/10.1214/18-AOS1745.full">[AoS version]</a><a href="slides/topK_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>The Likelihood Ratio Test in High-Dimensional Logistic Regression Is Asymptotically a <i>Rescaled</i> Chi-Square</b>  <br />  P. Sur, <u>Y. Chen</u>, E. J. Candes, <i>Probability Theory and Related Fields</i>, vol. 175, no. 1-2, pp.487â€“558, October 2019.  <a href="publications/LRT_HighDim_PTRF.pdf">[paper]</a><a href="publications/supplement_LRT.pdf">[supplement]</a><a href="slides/LRT_HighDim_slides.pdf">[slides]</a><a href="codes/Code_LRT.zip">[code]</a></p>
</li>
</ol>
<h2>2016</h2>
<ol>
<li><p><b>The Projected Power Method: An Efficient Algorithm for Joint Alignment from Pairwise Differences</b>  <br />  <u>Y. Chen</u> and E. J. Candes, <i>Communications on Pure and Applied Mathematics</i>, vol. 71, issue 8, pp. 1648-1714, August 2018.  <a href="publications/nonconvexAlign.pdf">[paper]</a><a href="slides/Alignment_slides.pdf">[slides]</a><a href="codes/code_NonconvexAlign.zip">[code]</a>
</p>
</li>
<li><p><b>Community Recovery in Graphs with Locality</b>  <br />  <u>Y. Chen</u>, G. Kamath, C. Suh, and D. Tse, <i>International Conference on Machine Learning (ICML)</i>, June 2016.  <a href="http://arxiv.org/abs/1602.03828">[paper]</a><a href="publications/Locality_ICML.pdf">[ICML version]</a><a href="slides/cgsi_talk_np.pptx">[CGSI slides]</a><a href="slides/Locality_ICML_slides.pdf">[slides]</a><a href="https://chenyx04.github.io/Spectral-Stitching/">[Github repo]</a><a href="https://www.youtube.com/watch?v=OQzm2jdbx8I&amp;list=PLZDU8a6AcnujAG3OScWbsibUVEbrfMdRB&amp;index=4">[lecture by D. Tse]</a> 

</p>
</li>
<li><p><b>Resolving Phase Ambiguity in Dual-Echo Dixon Imaging Using a Projected Power Method</b> <br /> T. Zhang, <u>Y. Chen</u>, S. Bao, M. Alley, J. M. Pauly, B. Hargreaves, S. S. Vasanawala, <i>Magnetic Resonance in Medicine</i>, vol. 77, no. 5, pp. 2066 - 2076, May 2017. <a href="http://onlinelibrary.wiley.com/doi/10.1002/mrm.26287/abstract">[paper]</a><a href="http://mrsrl.stanford.edu/~tao/software.html">[webpage]</a><a href="http://mrsrl.stanford.edu/~tao/docs/archive/DualEchoDixon.tar.gz">[code]</a></p>
</li>
</ol>
<h2>2015 </h2>
<ol>
<li><p><b>Solving Random Quadratic Systems of Equations Is Nearly as Easy as Solving Linear Systems</b>  <br />  <u>Y. Chen</u> and E. J. Candes, <i>Communications on Pure and Applied Mathematics</i>, vol. 70, issue 5, pp. 822 - 883, May 2017.  <a href="publications/TruncatedWF_CPAM.pdf">[paper]</a><a href="publications/TWF_NIPS.pdf">[NIPS version]</a><a href="publications/supplement_TWF.pdf">[supplement]</a><a href="TWF/">[webpage and code]</a><a href="slides//TWF_slides.pdf">[slides]</a>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;<b style="color: FireBrick">ICCM Best Paper Award (Gold Medal)</b>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;<b style="color: FireBrick">Finalist, Best Paper Prize for Young Researchers in Continuous Optimization</b>
<br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/TWF_NIPS.pdf">NIPS 2015</a> <b>(oral)</b>
</p>
</li>
<li><p><b>Spectral MLE:  Top-<i>K</i>  Rank Aggregation from Pairwise Comparisons</b> <br /> <u>Y. Chen</u> and C. Suh, <i>International Conference on Machine Learning (ICML)</i>, July 2015. <a href="http://arxiv.org/abs/1504.07218">[paper]</a><a href="publications/rank_top_ICML.pdf">[ICML version]</a>
</p>
</li>
<li><p><b>Information Recovery from Pairwise Measurements</b> <br /> <u>Y. Chen</u>, C. Suh, and A. J. Goldsmith, <i>IEEE Trans. on Info. Theory</i>, vol. 62, no. 10, pp. 5881 - 5905, Oct. 2016. <a href="publications/PairwiseIR_TIT.pdf">[paper]</a><a href="slides/GraphIR_Slides.pdf">[slides]</a> <br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/PairwiseIR_ISIT.pdf">ISIT 2014</a> and <a href="publications/graphIR_isit.pdf">ISIT 2015</a>
</p>
</li>
<li><p><b>Robust Self-Navigated Body MRI Using Dense Coil Arrays</b> <br /> T. Zhang, J. Y. Cheng, <u>Y. Chen</u>, D. G. Nishimura, J. M. Pauly, and S. S. Vasanawala, <i>Magnetic Resonance in Medicine</i>, vol. 76, no. 1, pp. 197 - 205, 2016. <a href="http://onlinelibrary.wiley.com/doi/10.1002/mrm.25858/abstract">[paper]</a><a href="http://mrsrl.stanford.edu/~tao/software.html">[webpage]</a><a href="http://mrsrl.stanford.edu/~tao/docs/archive/CoilClusteringDemo.tar.gz">[code]</a></p>
</li>
</ol>
<h2>2014</h2>
<ol>
<li><p><b>Near-Optimal Joint Object Matching via Convex Relaxation</b> <br /> <u>Y. Chen</u>, L. Guibas, and Q. Huang, <i>International Conference on Machine Learning (ICML)</i>, June 2014. <a href="https://arxiv.org/abs/1402.1473">[paper]</a><a href="publications/Matching_ICML.pdf">[ICML version]</a><a href="slides//matching_slides.pdf">[slides]</a><a href="codes/code_MatchLift.zip">[code]</a>
</p>
</li>
<li><p><b>Scalable Semidefinite Relaxation for Maximum A Posterior Estimation</b> <br /> Q. Huang, <u>Y. Chen</u>, and L. Guibas, <i>International Conference on Machine Learning (ICML)</i>, June 2014. <a href="publications/MRF_ICML.pdf">[paper]</a><a href="slides//MRF_ICML_slides.pdf">[slides]</a>
</p>
</li>
<li><p><b>Backing off from Infinity: Performance Bounds via Concentration of Spectral Measure for Random MIMO Channels</b> <br /> <u>Y. Chen</u>, A. J. Goldsmith, and Y. C. Eldar,  <i>IEEE Trans. on Info. Theory</i>, vol. 61, no. 1, pp. 366 - 387, Jan. 2015. <a href="publications/NonasymptoticMIMO.pdf">[paper]</a></p>
</li>
</ol>
<h2>2013</h2>
<ol>
<li><p><b>Exact and Stable Covariance Estimation from Quadratic Sampling via Convex Programming</b> <br />  <u>Y. Chen</u>, Y. Chi, and A. J. Goldsmith, <i>IEEE Trans. on Info. Theory</i>, vol. 61, no. 7, pp. 4034 - 4059, July 2015.  <a href="publications/CovEst.pdf">[paper]</a><a href="slides/CovEst_slides.pdf">[slides]</a> <br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/CovEst_ISIT_Final.pdf">ISIT 2014</a> and <a href="publications/CovEst_ICASSP.pdf">ICASSP 2014</a>
</p>
</li>
<li><p><b>Robust Spectral Compressed Sensing via Structured Matrix Completion</b> <br /> <u>Y. Chen</u> and Y. Chi, <i>IEEE Trans. on Info. Theory</i>, vol. 60, no. 10, pp. 6576 - 6601, Oct. 2014. <a href="publications/SpectralCS.pdf">[paper]</a><a href="publications/SpectralCS_ICML.pdf">[ICML version]</a><a href="slides/SpectralCS_slides.pdf">[slides]</a> <br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/SpectralCS.pdf">ICML 2013</a> (full oral)
</p>
</li>
<li><p><b>Compressive Two-Dimensional Harmonic Retrieval via Atomic Norm Minimization</b> <br /> Y. Chi and <u>Y. Chen</u>, <i>IEEE Trans. on Signal Processing</i>, vol. 63, no. 4, pp. 1030 - 1042, Feb. 2015. <a href="publications/atomic2D.pdf">[paper]</a>
</p>
</li>
<li><p><b>Minimax Capacity Loss under Sub-Nyquist Universal Sampling</b> <br /> <u>Y. Chen</u>, A. J. Goldsmith, and Y. C. Eldar, <i>IEEE Trans. on Info. Theory</i>, vol. 63, no. 6, pp. 3348 - 3367, June 2017.  <a href="publications/MinimaxSampling_TIT.pdf">[paper]</a><a href="slides/MinimaxSampling_Slides_YChen.pdf">[slides]</a> <br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/Minimax_ISIT.pdf">ISIT 2013</a> </p>
</li>
</ol>
<h2>2012</h2>
<ol>
<li><p><b>Channel Capacity under Sub-Nyquist Nonuniform Sampling</b> <br /> <u>Y. Chen</u>, A. J. Goldsmith, and Y. C. Eldar,  <i>IEEE Trans. on Info. Theory</i>, vol. 60, no. 8, pp. 4739 - 4756, Aug. 2014. <a href="publications/NonuniformSampling.pdf">[paper]</a><br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/NonuniformSampling_ISIT.pdf">ISIT 2012</a></p>
</li>
</ol>
<h2>2011</h2>
<ol>
<li><p><b>Shannon Meets Nyquist: Capacity of Sampled Gaussian Channels</b> <br /> <u>Y. Chen</u>, Y. C. Eldar, and A. J. Goldsmith,  <i>IEEE Trans. on Info. Theory</i>, vol. 59, no. 8, pp. 4889 - 4914 , Aug. 2013. <a href="publications/ChannelCap.pdf">[paper]</a><a href="slides/Shannon_Meets_Nyquist.pptx">[slides]</a> <br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/SampledCapacity_ICASSP.pdf">ICASSP 2011</a>  
</p>
</li>
<li><p><b>On the Role of Mobility on Multi-message Gossip</b> <br /> <u>Y. Chen</u>, S. Shakkottai and J. G. Andrews, <i>IEEE Trans. on Info. Theory</i>, vol. 59, no. 6, pp. 3953 - 3970, June 2013. <a href="publications/Journal_GossipMobile.pdf">[paper]</a><a href="slides/MobileGossip_Slides_YuxinChen.pdf">[slides]</a> <br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/Infocom_GossipMobile.pdf">INFOCOM 2011</a> (full oral)</p>
</li>
</ol>
<h2>2010</h2>
<ol>
<li><p><b>An Upper Bound on Multi-hop Transmission Capacity with Dynamic Routing Selection</b> <br /> <u>Y. Chen</u> and J. G. Andrews,  <i>IEEE Trans. on Info. Theory</i>, vol. 58, no. 6, pp. 3751 - 3765, June 2012. <a href="publications/multihop.pdf">[paper]</a> <br /> &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&#8201;&mdash;&#8201;appeared in part in <a href="publications/multihop_ISIT.pdf">ISIT 2010</a></p>
</li>
</ol>
<div id="footer">
<div id="footer-text">
Page generated 2025-10-20 11:01:07 EDT, by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
(<a href="Publications_year.jemdoc">source</a>)
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
